{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "importing file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(fname: str) -> pd.DataFrame:\n",
    "    \"\"\"\n",
    "    Loads a dataset from a CSV file.\n",
    "\n",
    "    Parameters:\n",
    "    fname (str): The location of the CSV file.\n",
    "\n",
    "    Returns:\n",
    "    pd.DataFrame: The loaded dataset (DataFrame).\n",
    "    \"\"\"\n",
    "    data = pd.read_csv(fname)\n",
    "    print(f\"Data Shape: {data.shape}\")\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (32581, 12)\n"
     ]
    }
   ],
   "source": [
    "FNAME = 'data/raw/credit_risk_dataset.csv'\n",
    "data = load_data(FNAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
      "0          22          59000                  RENT              123.0   \n",
      "1          21           9600                   OWN                5.0   \n",
      "2          25           9600              MORTGAGE                1.0   \n",
      "3          23          65500                  RENT                4.0   \n",
      "4          24          54400                  RENT                8.0   \n",
      "\n",
      "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_status  \\\n",
      "0    PERSONAL          D      35000          16.02            1   \n",
      "1   EDUCATION          B       1000          11.14            0   \n",
      "2     MEDICAL          C       5500          12.87            1   \n",
      "3     MEDICAL          C      35000          15.23            1   \n",
      "4     MEDICAL          C      35000          14.27            1   \n",
      "\n",
      "   loan_percent_income cb_person_default_on_file  cb_person_cred_hist_length  \n",
      "0                 0.59                         Y                           3  \n",
      "1                 0.10                         N                           2  \n",
      "2                 0.57                         N                           3  \n",
      "3                 0.53                         N                           2  \n",
      "4                 0.55                         Y                           4  \n"
     ]
    }
   ],
   "source": [
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "screenshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Screenshot data head](screenshot_for_data_head.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_input_output(data: pd.DataFrame, target_col: str) -> tuple:\n",
    "    \"\"\"\n",
    "    Splits the dataset into input features and target variable.\n",
    "\n",
    "    Parameters:\n",
    "    data (pd.DataFrame): The complete dataset.\n",
    "    target_col (str): The name of the column containing the target variable.\n",
    "\n",
    "    Returns:\n",
    "    tuple: A tuple containing:\n",
    "        - X (pd.DataFrame): The input features after dropping the target column.\n",
    "        - y (pd.Series): The target variable extracted from the dataset.\n",
    "    \"\"\"\n",
    "    print(f\"Original data shape: {data.shape}\")\n",
    "\n",
    "    X = data.drop(columns=[target_col])\n",
    "\n",
    "    y = data[target_col]\n",
    "\n",
    "    print(f\"X data shape: {X.shape}\")\n",
    "    print(f\"y data shape: {y.shape}\")\n",
    "\n",
    "    return X, y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original data shape: (32581, 12)\n",
      "X data shape: (32581, 11)\n",
      "y data shape: (32581,)\n",
      "   person_age  person_income person_home_ownership  person_emp_length  \\\n",
      "0          22          59000                  RENT              123.0   \n",
      "1          21           9600                   OWN                5.0   \n",
      "2          25           9600              MORTGAGE                1.0   \n",
      "3          23          65500                  RENT                4.0   \n",
      "4          24          54400                  RENT                8.0   \n",
      "\n",
      "  loan_intent loan_grade  loan_amnt  loan_int_rate  loan_percent_income  \\\n",
      "0    PERSONAL          D      35000          16.02                 0.59   \n",
      "1   EDUCATION          B       1000          11.14                 0.10   \n",
      "2     MEDICAL          C       5500          12.87                 0.57   \n",
      "3     MEDICAL          C      35000          15.23                 0.53   \n",
      "4     MEDICAL          C      35000          14.27                 0.55   \n",
      "\n",
      "  cb_person_default_on_file  cb_person_cred_hist_length  \n",
      "0                         Y                           3  \n",
      "1                         N                           2  \n",
      "2                         N                           3  \n",
      "3                         N                           2  \n",
      "4                         Y                           4  \n",
      "0    1\n",
      "1    0\n",
      "2    1\n",
      "3    1\n",
      "4    1\n",
      "Name: loan_status, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "TARGET_COL = 'loan_status'  \n",
    "\n",
    "X, y = split_input_output(data, TARGET_COL)\n",
    "\n",
    "print(X.head())\n",
    "print(y.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "screenshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screenshot splitting x and y](screenshot_for_split_x_y.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "def split_train_test(X: pd.DataFrame, y: pd.Series, test_size: float, random_state: int = None) -> tuple:\n",
    "    \"\"\"\n",
    "    Splits the dataset into training and testing sets.\n",
    "\n",
    "    Parameters:\n",
    "    X (DataFrame): The input features.\n",
    "    y (Series): The target variable.\n",
    "    test_size (float): The proportion of the dataset to include in the test split.\n",
    "    random_state (int, optional): Controls the shuffling applied to the data before applying the split. Default is None.\n",
    "\n",
    "    Returns:\n",
    "    Tuple[DataFrame, DataFrame, Series, Series]: \n",
    "        - X_train (DataFrame): The training set for features.\n",
    "        - X_test (DataFrame): The testing set for features.\n",
    "        - y_train (Series): The training set for the target variable.\n",
    "        - y_test (Series): The testing set for the target variable.\n",
    "    \"\"\"\n",
    "    X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=test_size, random_state=random_state, stratify=y)\n",
    "\n",
    "    print(f\"X train shape: {X_train.shape}\")\n",
    "    print(f\"X test shape: {X_test.shape}\")\n",
    "    print(f\"y train shape: {y_train.shape}\")\n",
    "    print(f\"y test shape: {y_test.shape}\")\n",
    "\n",
    "    return X_train, X_test, y_train, y_test\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X train shape: (26064, 11)\n",
      "X test shape: (6517, 11)\n",
      "y train shape: (26064,)\n",
      "y test shape: (6517,)\n",
      "X train shape: (3258, 11)\n",
      "X test shape: (3259, 11)\n",
      "y train shape: (3258,)\n",
      "y test shape: (3259,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_non_train, y_train, y_non_train = split_train_test(X, y, test_size=0.2, random_state=42)\n",
    "\n",
    "X_valid, X_test, y_valid, y_test = split_train_test(X_non_train, y_non_train, test_size=0.5, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "import os\n",
    "\n",
    "def serialize_data(data: object, path: str) -> None:\n",
    "    \"\"\"\n",
    "    Serializes the given data and saves it to the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    data (object): The instance or object that you want to serialize.\n",
    "    path (str): The file path where the serialized data will be saved.\n",
    "\n",
    "    Returns:\n",
    "    None: This function does not return a value.\n",
    "    \"\"\"\n",
    "    dir_name = os.path.dirname(path)\n",
    "    if not os.path.exists(dir_name):\n",
    "        print(f\"Warning: The directory '{dir_name}' does not exist. Please create it before serialization.\")\n",
    "        return\n",
    "    joblib.dump(data, path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "serialize_data(X_train, \"data/interim/X_train.pkl\")\n",
    "serialize_data(y_train, \"data/interim/y_train.pkl\")\n",
    "serialize_data(X_test, \"data/interim/X_test.pkl\")\n",
    "serialize_data(y_test, \"data/interim/y_test.pkl\")\n",
    "serialize_data(X_valid, \"data/interim/X_valid.pkl\")\n",
    "serialize_data(y_valid, \"data/interim/y_valid.pkl\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "screenshot"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![screenshot serialize working](screenshot_serialize_working.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "def deserialize_data(path: str) -> object:\n",
    "    \"\"\"\n",
    "    Deserializes data from the specified path.\n",
    "\n",
    "    Parameters:\n",
    "    path (str): The path where the serialized data is located.\n",
    "\n",
    "    Returns:\n",
    "    object: The deserialized data.\n",
    "    \"\"\"\n",
    "    data = joblib.load(path)\n",
    "    return data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = deserialize_data(\"data/interim/X_train.pkl\")\n",
    "y_train = deserialize_data(\"data/interim/y_train.pkl\")\n",
    "X_test = deserialize_data(\"data/interim/X_test.pkl\")\n",
    "y_test = deserialize_data(\"data/interim/y_test.pkl\")\n",
    "X_valid = deserialize_data(\"data/interim/X_valid.pkl\")\n",
    "y_valid = deserialize_data(\"data/interim/y_valid.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
